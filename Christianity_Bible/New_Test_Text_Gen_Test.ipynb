{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/compat/compat.py:175: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from random import randint\n",
    "from pickle import load\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename,'r')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "model = tf.keras.models.load_model('new_test_model_2.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = pickle.load(open('new_test_tokenizer_2.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sequence from a language model\n",
    "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
    "    result = list()\n",
    "    in_text = seed_text\n",
    "    # generate a fixed number of words\n",
    "    for _ in range(n_words):\n",
    "        # encode the text as integer\n",
    "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        # truncate sequences to a fixed length\n",
    "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "        # predict probabilities for each word\n",
    "        yhat = model.predict_classes(encoded, verbose=0)\n",
    "        # map predicted word index to word\n",
    "        out_word = ''\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == yhat:\n",
    "                out_word = word\n",
    "                break\n",
    "        # append to input\n",
    "        in_text += ' ' + out_word\n",
    "        result.append(out_word)\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_new_testament = load_doc('clean_new_testament.txt').split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_text_generator(seed_corpus):\n",
    "    seed_text = clean_new_testament[randint(0,len(seed_corpus))]\n",
    "    return seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made manifest in the spirit of god for we are the gospel of god and the lord jesus christ and the word of god is\n"
     ]
    }
   ],
   "source": [
    "# generate new text\n",
    "seed_text = 'inner man that christ may dwell in your hearts by faith that ye being rooted and grounded in love may be able to comprehend with all saints what is the breadth and length and depth and height and to know the love of christ which passeth knowledge that ye might be'\n",
    "generated = generate_seq(model, tokenizer, 50, seed_text, 25)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "but the angel said unto him fear not zacharias for thy prayer is heard and thy wife elisabeth shall bear thee a son and thou shalt call his name john\n",
      "\n",
      "and the lord jesus answered and said unto them i will not be thrown down and the chief priests and\n"
     ]
    }
   ],
   "source": [
    "##### select a seed text\n",
    "seed_text = clean_new_testament[randint(0,len(clean_new_testament))]\n",
    "print(seed_text + '\\n')\n",
    "\n",
    "# generate new text\n",
    "generated = generate_seq(model, tokenizer, 50, seed_text, 20)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i speak not of you all i know whom i have chosen but that the scripture may be fulfilled he that eateth bread with me hath lifted up his heel against me\n",
      "\n",
      "and i will not be hated of the lord and i will not be found thee and fresh and be not afraid and the lord\n"
     ]
    }
   ],
   "source": [
    "##### select a seed text\n",
    "seed_text = clean_new_testament[randint(0,len(clean_new_testament))]\n",
    "print(seed_text + '\\n')\n",
    "\n",
    "# generate new text\n",
    "generated = generate_seq(model, tokenizer, 50, seed_text, 25)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the farther side of jordan and the people resort unto him again and as he was wont he taught them again and the pharisees came to him and asked him is it lawful for a man to put away his wife tempting him and he answered and said unto them what\n",
      "\n",
      "shall i liken thee and he that hath spoken unto me i will come unto him and he said unto them i am not worthy to be perfected and shall be found thee and he that is least for he was a jew and of the sea and they sung\n"
     ]
    }
   ],
   "source": [
    "##### select a seed text\n",
    "seed_text = new_test_sequences[randint(0,len(new_test_sequences))]\n",
    "print(seed_text + '\\n')\n",
    "\n",
    "# generate new text\n",
    "generated = generate_seq(model, tokenizer, 50, seed_text, 50)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "off thy shoes from thy feet for the place where thou standest is holy ground i have seen i have seen the affliction of my people which is in egypt and i have heard their groaning and am come down to deliver them and now come i will send thee into\n",
      "\n",
      "the oven and the lord and the son of man is the son of god and the lord was dried up and the people was a galilaean and the scribes and pharisees was come to the chief priests and the scribes and pharisees watched him and he that was called\n"
     ]
    }
   ],
   "source": [
    "##### select a seed text\n",
    "seed_text = new_test_sequences[randint(0,len(new_test_sequences))]\n",
    "print(seed_text + '\\n')\n",
    "\n",
    "# generate new text\n",
    "generated = generate_seq(model, tokenizer, 50, seed_text, 50)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our hands commanding his accusers to come unto thee by examining of whom thyself mayest take knowledge of all these things whereof we accuse him and the jews also assented saying that these things were so then paul after that the governor had beckoned unto him to speak answered forasmuch as\n",
      "\n",
      "he was a galilaean and not i will not be ashamed and he said unto him i will not tempt thee that i may not be thrown down and the chief priests and scribes and said unto him thomas himself and the chief priests and the chief priests and officers\n"
     ]
    }
   ],
   "source": [
    "##### select a seed text\n",
    "seed_text = new_test_sequences[randint(0,len(new_test_sequences))]\n",
    "print(seed_text + '\\n')\n",
    "\n",
    "# generate new text\n",
    "generated = generate_seq(model, tokenizer, 50, seed_text, 50)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered into the mans house and he shewed us how he had seen an angel in his house which stood and said unto him send men to joppa and call for simon whose surname is peter who shall tell thee words whereby thou and all thy house shall be saved and\n",
      "\n",
      "he said unto him thou hast given thee to be a worshipper of god and the same day and he said unto him i will not be thrown down and he said unto them why callest thou me good things shall i be a sinner and the son of man\n"
     ]
    }
   ],
   "source": [
    "##### select a seed text\n",
    "seed_text = new_test_sequences[randint(0,len(new_test_sequences))]\n",
    "print(seed_text + '\\n')\n",
    "\n",
    "# generate new text\n",
    "generated = generate_seq(model, tokenizer, 50, seed_text, 50)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great city which reigneth over the kings of the earth and after these things i saw another angel come down from heaven having great power and the earth was lightened with his glory and he cried mightily with a strong voice saying babylon the great is fallen is fallen and is\n",
      "\n",
      "found that the son of man is betrayed to be a performance of the earth and the same is the\n"
     ]
    }
   ],
   "source": [
    "##### select a seed text\n",
    "seed_text = new_test_sequences[randint(0,len(new_test_sequences))]\n",
    "print(seed_text + '\\n')\n",
    "\n",
    "# generate new text\n",
    "generated = generate_seq(model, tokenizer, 50, seed_text, 20)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i have set before thee an open door and no man can shut it for thou hast a little strength and hast kept my word and hast not denied my name behold i will make them of the synagogue of satan which say they are jews and are not but do\n",
      "\n",
      "ye not slothful nor free man is not in the law and the lord jesus christ and the lord jesus\n"
     ]
    }
   ],
   "source": [
    "##### select a seed text\n",
    "seed_text = new_test_sequences[randint(0,len(new_test_sequences))]\n",
    "print(seed_text + '\\n')\n",
    "\n",
    "# generate new text\n",
    "generated = generate_seq(model, tokenizer, 50, seed_text, 20)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to the acknowledging of the truth and that they may recover themselves out of the snare of the devil who are taken captive by him at his will this know also that in the last days perilous times shall come for men shall be lovers of their own selves covetous boasters\n",
      "\n",
      "proud blasphemers disobedient to meat in perils in the midst of the earth and the third angel sounded and the\n"
     ]
    }
   ],
   "source": [
    "##### select a seed text\n",
    "seed_text = new_test_sequences[randint(0,len(new_test_sequences))]\n",
    "print(seed_text + '\\n')\n",
    "\n",
    "# generate new text\n",
    "generated = generate_seq(model, tokenizer, 50, seed_text, 20)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and ever and cast their crowns before the throne saying thou art worthy o lord to receive glory and honour and power for thou hast created all things and for thy pleasure they are and were created and i saw in the right hand of him that sat on the throne\n",
      "\n",
      "and the third angel poured out his vial upon the sea and the seven spirits of the dead and the\n"
     ]
    }
   ],
   "source": [
    "##### select a seed text\n",
    "seed_text = new_test_sequences[randint(0,len(new_test_sequences))]\n",
    "print(seed_text + '\\n')\n",
    "\n",
    "# generate new text\n",
    "generated = generate_seq(model, tokenizer, 50, seed_text, 20)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people when they knew it followed him and he received them and spake unto them of the kingdom of god and healed them that had need of healing and when the day began to wear away then came the twelve and said unto him send the multitude away that they may\n",
      "\n",
      "be broken up and the chief priests and elders and the chief priests and the next day was in the\n"
     ]
    }
   ],
   "source": [
    "##### select a seed text\n",
    "seed_text = new_test_sequences[randint(0,len(new_test_sequences))]\n",
    "print(seed_text + '\\n')\n",
    "\n",
    "# generate new text\n",
    "generated = generate_seq(model, tokenizer, 50, seed_text, 20)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inner man that christ may dwell in your hearts by faith that ye being rooted and grounded in love may be able to comprehend with all saints what is the breadth and length and depth and height and to know the love of christ which passeth knowledge that ye might be\n",
      "\n",
      "grateful sent ye the penalty of the blazing fire submits the earth in his presence and we have made the night in adoration of them and the celebration of bliss wellnigh vanish the boiling rank wine firm and square on the day of judgment and that they may turn away\n"
     ]
    }
   ],
   "source": [
    "##### select a seed text\n",
    "seed_text = new_test_sequences[randint(0,len(new_test_sequences))]\n",
    "print(seed_text + '\\n')\n",
    "\n",
    "# generate new text\n",
    "generated = generate_seq(model, tokenizer, 50, seed_text, 50)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and thou hast prepared for you a son that is hidden from us and teach thee not from the truth and we have sent down to thee a messenger from thy lord and cherisher and glorify me with my lord and my brother is he who has sent down to\n"
     ]
    }
   ],
   "source": [
    "# generate new text\n",
    "generated = generate_seq(model, tokenizer, 50, 'call upon me i will respond to you', 50)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not unto you and the same is the husbandman and the sand of the earth and kindreds and brimstone of god and breaking with arabia and hell testified of the\n"
     ]
    }
   ],
   "source": [
    "# generate new text\n",
    "generated = generate_seq(model, tokenizer, 50, 'they seek forgivness', 30)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
