{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "from random import randint\n",
    "from pickle import load\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# import tensorflow.compat.v1 as tf\n",
    "# tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "    file = open(filename,'r')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_to_tokens_to_sequences(corpus,sequence_length=50):\n",
    "    tokens = ' '.join(corpus)\n",
    "    tokens = tokens.split()\n",
    "    # organize into sequences of tokens\n",
    "    length = sequence_length + 1\n",
    "    sequences = []\n",
    "    for i in range(length, len(tokens)):\n",
    "        # select sequence of tokens\n",
    "        seq = tokens[i-length:i]\n",
    "        # convert into a line\n",
    "        line = ' '.join(seq)\n",
    "        # store\n",
    "        sequences.append(line)\n",
    "    print('Total Sequences: %d' % len(sequences))\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_old_test = load_doc('/Users/tcbon/Desktop/Coding/Metis/Bootcamp/Project_4/Christianity - Bible/clean_old_testament.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_new_test = load_doc('/Users/tcbon/Desktop/Coding/Metis/Bootcamp/Project_4/Christianity - Bible/clean_new_testament.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 609366\n"
     ]
    }
   ],
   "source": [
    "# saving old testament sequences to txt file\n",
    "old_test_sequences = corpus_to_tokens_to_sequences(clean_old_test)\n",
    "\n",
    "resave_old_test = False\n",
    "if resave_old_test == True:\n",
    "    out_filename = 'old_test_sequences.txt'\n",
    "    save_doc(sequences, out_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 180528\n"
     ]
    }
   ],
   "source": [
    "# saving new testament sequences to txt file\n",
    "new_test_sequences = corpus_to_tokens_to_sequences(clean_new_test)\n",
    "\n",
    "resave_new_test = False\n",
    "if resave_new_test == True:\n",
    "    out_filename = 'new_test_sequences.txt'\n",
    "    save_doc(sequences, out_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old Testament Text Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 50, 50)            537550    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 50, 100)           60400     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10751)             1085851   \n",
      "=================================================================\n",
      "Total params: 1,774,301\n",
      "Trainable params: 1,774,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From /anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "609366/609366 [==============================] - 778s 1ms/sample - loss: 5.3851 - acc: 0.1653\n",
      "Epoch 2/100\n",
      "609366/609366 [==============================] - 773s 1ms/sample - loss: 4.8515 - acc: 0.2020\n",
      "Epoch 3/100\n",
      "609366/609366 [==============================] - 779s 1ms/sample - loss: 4.6198 - acc: 0.2164\n",
      "Epoch 4/100\n",
      "609366/609366 [==============================] - 783s 1ms/sample - loss: 4.4573 - acc: 0.2279\n",
      "Epoch 5/100\n",
      "609366/609366 [==============================] - 784s 1ms/sample - loss: 4.3421 - acc: 0.2351\n",
      "Epoch 6/100\n",
      "609366/609366 [==============================] - 786s 1ms/sample - loss: 4.2525 - acc: 0.2411\n",
      "Epoch 7/100\n",
      "609366/609366 [==============================] - 786s 1ms/sample - loss: 4.1789 - acc: 0.2469\n",
      "Epoch 8/100\n",
      "609366/609366 [==============================] - 786s 1ms/sample - loss: 4.1119 - acc: 0.2517\n",
      "Epoch 9/100\n",
      "609366/609366 [==============================] - 789s 1ms/sample - loss: 4.0534 - acc: 0.2568\n",
      "Epoch 10/100\n",
      "609366/609366 [==============================] - 787s 1ms/sample - loss: 4.0032 - acc: 0.2610\n",
      "Epoch 11/100\n",
      "609366/609366 [==============================] - 788s 1ms/sample - loss: 3.9578 - acc: 0.2654\n",
      "Epoch 12/100\n",
      "609366/609366 [==============================] - 788s 1ms/sample - loss: 3.9171 - acc: 0.2690\n",
      "Epoch 13/100\n",
      "609366/609366 [==============================] - 788s 1ms/sample - loss: 3.8808 - acc: 0.2720\n",
      "Epoch 14/100\n",
      "609366/609366 [==============================] - 788s 1ms/sample - loss: 3.8468 - acc: 0.2749\n",
      "Epoch 15/100\n",
      "609366/609366 [==============================] - 788s 1ms/sample - loss: 3.8155 - acc: 0.2783\n",
      "Epoch 16/100\n",
      "609366/609366 [==============================] - 789s 1ms/sample - loss: 3.7848 - acc: 0.2812\n",
      "Epoch 17/100\n",
      "609366/609366 [==============================] - 788s 1ms/sample - loss: 3.7580 - acc: 0.2841\n",
      "Epoch 18/100\n",
      "609366/609366 [==============================] - 788s 1ms/sample - loss: 3.7312 - acc: 0.2857\n",
      "Epoch 19/100\n",
      "609366/609366 [==============================] - 790s 1ms/sample - loss: 3.7077 - acc: 0.2883\n",
      "Epoch 20/100\n",
      "609366/609366 [==============================] - 791s 1ms/sample - loss: 3.6839 - acc: 0.2907\n",
      "Epoch 21/100\n",
      "609366/609366 [==============================] - 790s 1ms/sample - loss: 3.6626 - acc: 0.2933\n",
      "Epoch 22/100\n",
      "609366/609366 [==============================] - 789s 1ms/sample - loss: 3.6415 - acc: 0.2952\n",
      "Epoch 23/100\n",
      "609366/609366 [==============================] - 789s 1ms/sample - loss: 3.6215 - acc: 0.2974\n",
      "Epoch 24/100\n",
      "609366/609366 [==============================] - 789s 1ms/sample - loss: 3.6036 - acc: 0.2989\n",
      "Epoch 25/100\n",
      "609366/609366 [==============================] - 790s 1ms/sample - loss: 3.5851 - acc: 0.3006\n",
      "Epoch 26/100\n",
      "609366/609366 [==============================] - 790s 1ms/sample - loss: 3.5691 - acc: 0.3032\n",
      "Epoch 27/100\n",
      "609366/609366 [==============================] - 791s 1ms/sample - loss: 3.5522 - acc: 0.3046\n",
      "Epoch 28/100\n",
      "609366/609366 [==============================] - 792s 1ms/sample - loss: 3.5371 - acc: 0.3063\n",
      "Epoch 29/100\n",
      "609366/609366 [==============================] - 791s 1ms/sample - loss: 3.5219 - acc: 0.3078\n",
      "Epoch 30/100\n",
      "609366/609366 [==============================] - 791s 1ms/sample - loss: 3.5084 - acc: 0.3092\n",
      "Epoch 31/100\n",
      "609366/609366 [==============================] - 790s 1ms/sample - loss: 3.4961 - acc: 0.3107\n",
      "Epoch 32/100\n",
      "609366/609366 [==============================] - 790s 1ms/sample - loss: 3.4829 - acc: 0.3122\n",
      "Epoch 33/100\n",
      "609366/609366 [==============================] - 790s 1ms/sample - loss: 3.4692 - acc: 0.3135\n",
      "Epoch 34/100\n",
      "609366/609366 [==============================] - 790s 1ms/sample - loss: 3.4596 - acc: 0.3143\n",
      "Epoch 35/100\n",
      "609366/609366 [==============================] - 791s 1ms/sample - loss: 3.4473 - acc: 0.3161\n",
      "Epoch 36/100\n",
      "609366/609366 [==============================] - 791s 1ms/sample - loss: 3.4370 - acc: 0.3172\n",
      "Epoch 37/100\n",
      "609366/609366 [==============================] - 792s 1ms/sample - loss: 3.4272 - acc: 0.3186\n",
      "Epoch 38/100\n",
      "609366/609366 [==============================] - 792s 1ms/sample - loss: 3.4166 - acc: 0.3193\n",
      "Epoch 39/100\n",
      "609366/609366 [==============================] - 791s 1ms/sample - loss: 3.4075 - acc: 0.3205\n",
      "Epoch 40/100\n",
      "609366/609366 [==============================] - 791s 1ms/sample - loss: 3.3979 - acc: 0.3212\n",
      "Epoch 41/100\n",
      "609366/609366 [==============================] - 791s 1ms/sample - loss: 3.3896 - acc: 0.3225\n",
      "Epoch 42/100\n",
      "609366/609366 [==============================] - 792s 1ms/sample - loss: 3.3813 - acc: 0.3237\n",
      "Epoch 43/100\n",
      "609366/609366 [==============================] - 795s 1ms/sample - loss: 3.3731 - acc: 0.3247\n",
      "Epoch 44/100\n",
      "609366/609366 [==============================] - 831s 1ms/sample - loss: 3.3657 - acc: 0.3255\n",
      "Epoch 45/100\n",
      " 34816/609366 [>.............................] - ETA: 14:37 - loss: 3.2938 - acc: 0.3313"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6c9456d4798b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mold_test_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mold_test_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(old_test_sequences)\n",
    "sequences = tokenizer.texts_to_sequences(old_test_sequences)\n",
    "\n",
    "# vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    " \n",
    "# separate into input and output\n",
    "sequences = array(sequences)\n",
    "X, y = sequences[:,:-1], sequences[:,-1]\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "seq_length = X.shape[1]\n",
    " \n",
    "# define model\n",
    "old_test_model = Sequential([\n",
    "    Embedding(vocab_size, 50, input_length=seq_length),\n",
    "    LSTM(100, return_sequences=True),\n",
    "    LSTM(100),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "print(old_test_model.summary())\n",
    "# compile model\n",
    "old_test_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit model\n",
    "old_test_model.fit(X, y, batch_size=128, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the model to file\n",
    "old_test_model.save('old_test_model_3.hdf5')\n",
    "# save the tokenizer\n",
    "pickle.dump(tokenizer, open('old_test_tokenizer_3.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Testament Text Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 50, 50)            300350    \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 50, 100)           60400     \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 6007)              606707    \n",
      "=================================================================\n",
      "Total params: 1,057,957\n",
      "Trainable params: 1,057,957\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "180528/180528 [==============================] - 182s 1ms/sample - loss: 5.8808 - acc: 0.0820\n",
      "Epoch 2/50\n",
      "180528/180528 [==============================] - 182s 1ms/sample - loss: 5.4081 - acc: 0.1216\n",
      "Epoch 3/50\n",
      "180528/180528 [==============================] - 186s 1ms/sample - loss: 5.1877 - acc: 0.1425\n",
      "Epoch 4/50\n",
      "180528/180528 [==============================] - 188s 1ms/sample - loss: 5.0663 - acc: 0.1488\n",
      "Epoch 5/50\n",
      "180528/180528 [==============================] - 184s 1ms/sample - loss: 4.9543 - acc: 0.1553\n",
      "Epoch 6/50\n",
      "180528/180528 [==============================] - 188s 1ms/sample - loss: 4.8573 - acc: 0.1608\n",
      "Epoch 7/50\n",
      "180528/180528 [==============================] - 187s 1ms/sample - loss: 4.7720 - acc: 0.1648\n",
      "Epoch 8/50\n",
      "180528/180528 [==============================] - 179s 993us/sample - loss: 4.6930 - acc: 0.1691\n",
      "Epoch 9/50\n",
      "180528/180528 [==============================] - 181s 1ms/sample - loss: 4.6306 - acc: 0.1738\n",
      "Epoch 10/50\n",
      "180528/180528 [==============================] - 179s 991us/sample - loss: 4.5592 - acc: 0.1788\n",
      "Epoch 11/50\n",
      "180528/180528 [==============================] - 179s 993us/sample - loss: 4.4956 - acc: 0.1823\n",
      "Epoch 12/50\n",
      "180528/180528 [==============================] - 188s 1ms/sample - loss: 4.4455 - acc: 0.1856\n",
      "Epoch 13/50\n",
      "180528/180528 [==============================] - 187s 1ms/sample - loss: 4.3948 - acc: 0.1884\n",
      "Epoch 14/50\n",
      "180528/180528 [==============================] - 183s 1ms/sample - loss: 4.3879 - acc: 0.1905\n",
      "Epoch 15/50\n",
      "180528/180528 [==============================] - 179s 989us/sample - loss: 4.3351 - acc: 0.1951\n",
      "Epoch 16/50\n",
      "180528/180528 [==============================] - 179s 990us/sample - loss: 4.2814 - acc: 0.1993\n",
      "Epoch 17/50\n",
      "180528/180528 [==============================] - 176s 976us/sample - loss: 4.2317 - acc: 0.2029\n",
      "Epoch 18/50\n",
      "180528/180528 [==============================] - 172s 953us/sample - loss: 4.1851 - acc: 0.2057\n",
      "Epoch 19/50\n",
      "180528/180528 [==============================] - 177s 980us/sample - loss: 4.1425 - acc: 0.2089\n",
      "Epoch 20/50\n",
      "180528/180528 [==============================] - 180s 995us/sample - loss: 4.1026 - acc: 0.2108\n",
      "Epoch 21/50\n",
      "180528/180528 [==============================] - 175s 970us/sample - loss: 4.0632 - acc: 0.2140\n",
      "Epoch 22/50\n",
      "180528/180528 [==============================] - 175s 969us/sample - loss: 4.0248 - acc: 0.2163\n",
      "Epoch 23/50\n",
      "180528/180528 [==============================] - 175s 969us/sample - loss: 3.9886 - acc: 0.2193\n",
      "Epoch 24/50\n",
      "180528/180528 [==============================] - 177s 982us/sample - loss: 3.9566 - acc: 0.2222\n",
      "Epoch 25/50\n",
      "180528/180528 [==============================] - 182s 1ms/sample - loss: 3.9242 - acc: 0.2245\n",
      "Epoch 26/50\n",
      "180528/180528 [==============================] - 179s 994us/sample - loss: 3.8919 - acc: 0.2280\n",
      "Epoch 27/50\n",
      "180528/180528 [==============================] - 182s 1ms/sample - loss: 3.8648 - acc: 0.2297\n",
      "Epoch 28/50\n",
      "180528/180528 [==============================] - 184s 1ms/sample - loss: 3.8365 - acc: 0.2323\n",
      "Epoch 29/50\n",
      "180528/180528 [==============================] - 172s 950us/sample - loss: 3.8075 - acc: 0.2354\n",
      "Epoch 30/50\n",
      "180528/180528 [==============================] - 182s 1ms/sample - loss: 3.7809 - acc: 0.2372\n",
      "Epoch 31/50\n",
      "180528/180528 [==============================] - 179s 992us/sample - loss: 3.7548 - acc: 0.2402\n",
      "Epoch 32/50\n",
      "180528/180528 [==============================] - 180s 995us/sample - loss: 3.7295 - acc: 0.2426\n",
      "Epoch 33/50\n",
      "180528/180528 [==============================] - 179s 994us/sample - loss: 3.7061 - acc: 0.2448\n",
      "Epoch 34/50\n",
      "180528/180528 [==============================] - 178s 986us/sample - loss: 3.6808 - acc: 0.2481\n",
      "Epoch 35/50\n",
      "180528/180528 [==============================] - 180s 996us/sample - loss: 3.6577 - acc: 0.2505\n",
      "Epoch 36/50\n",
      "180528/180528 [==============================] - 183s 1ms/sample - loss: 3.6368 - acc: 0.2531\n",
      "Epoch 37/50\n",
      "180528/180528 [==============================] - 187s 1ms/sample - loss: 3.6132 - acc: 0.2561\n",
      "Epoch 38/50\n",
      "180528/180528 [==============================] - 181s 1ms/sample - loss: 3.5925 - acc: 0.2580\n",
      "Epoch 39/50\n",
      "180528/180528 [==============================] - 180s 998us/sample - loss: 3.5700 - acc: 0.2603\n",
      "Epoch 40/50\n",
      "180528/180528 [==============================] - 181s 1ms/sample - loss: 3.5492 - acc: 0.2628\n",
      "Epoch 41/50\n",
      "180528/180528 [==============================] - 182s 1ms/sample - loss: 3.5283 - acc: 0.2655\n",
      "Epoch 42/50\n",
      "180528/180528 [==============================] - 187s 1ms/sample - loss: 3.5077 - acc: 0.2683\n",
      "Epoch 43/50\n",
      "180528/180528 [==============================] - 183s 1ms/sample - loss: 3.4874 - acc: 0.2712\n",
      "Epoch 44/50\n",
      "180528/180528 [==============================] - 182s 1ms/sample - loss: 3.4680 - acc: 0.2726\n",
      "Epoch 45/50\n",
      "180528/180528 [==============================] - 178s 987us/sample - loss: 3.4490 - acc: 0.2756\n",
      "Epoch 46/50\n",
      "180528/180528 [==============================] - 184s 1ms/sample - loss: 3.4301 - acc: 0.2778\n",
      "Epoch 47/50\n",
      "180528/180528 [==============================] - 185s 1ms/sample - loss: 3.4117 - acc: 0.2801\n",
      "Epoch 48/50\n",
      "180528/180528 [==============================] - 179s 990us/sample - loss: 3.3931 - acc: 0.2821\n",
      "Epoch 49/50\n",
      "180528/180528 [==============================] - 183s 1ms/sample - loss: 3.3739 - acc: 0.2855\n",
      "Epoch 50/50\n",
      "180528/180528 [==============================] - 181s 1ms/sample - loss: 3.3554 - acc: 0.2879\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a34dddf60>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(new_test_sequences)\n",
    "sequences = tokenizer.texts_to_sequences(new_test_sequences)\n",
    "\n",
    "# vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    " \n",
    "# separate into input and output\n",
    "sequences = array(sequences)\n",
    "X, y = sequences[:,:-1], sequences[:,-1]\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "seq_length = X.shape[1]\n",
    " \n",
    "# define model\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, 50, input_length=seq_length),\n",
    "    LSTM(100, return_sequences=True),\n",
    "    LSTM(100),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "print(model.summary())\n",
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit model\n",
    "model.fit(X, y, batch_size=128, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to file\n",
    "model.save('new_test_model_2.hdf5')\n",
    "# save the tokenizer\n",
    "pickle.dump(tokenizer, open('new_test_tokenizer_2.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
