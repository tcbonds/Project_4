{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "from random import randint\n",
    "from pickle import load\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# import tensorflow.compat.v1 as tf\n",
    "# tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename,'r')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tokens to file, one dialog per line\n",
    "def save_doc(lines, filename):\n",
    "    data = '\\n'.join(lines)\n",
    "    file = open(filename, 'w')\n",
    "    file.write(data)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_to_tokens_to_sequences(corpus,sequence_length=50):\n",
    "    tokens = corpus.split()\n",
    "    # organize into sequences of tokens\n",
    "    length = sequence_length + 1\n",
    "    sequences = list()\n",
    "    for i in range(length, len(tokens)):\n",
    "        # select sequence of tokens\n",
    "        seq = tokens[i-length:i]\n",
    "        # convert into a line\n",
    "        line = ' '.join(seq)\n",
    "        # store\n",
    "        sequences.append(line)\n",
    "    print('Total Sequences: %d' % len(sequences))\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Torah\n",
    "clean_torah = load_doc('clean_torah.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 150182\n"
     ]
    }
   ],
   "source": [
    "# saving torahament sequences to txt file\n",
    "torah_sequences = corpus_to_tokens_to_sequences(clean_torah)\n",
    "out_filename = 'torah_sequences.txt'\n",
    "save_doc(torah_sequences, out_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torah Text Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 50, 50)            244200    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 50, 100)           60400     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4884)              493284    \n",
      "=================================================================\n",
      "Total params: 888,384\n",
      "Trainable params: 888,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From /anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "150182/150182 [==============================] - 164s 1ms/sample - loss: 5.6339 - acc: 0.1191\n",
      "Epoch 2/100\n",
      "150182/150182 [==============================] - 151s 1ms/sample - loss: 5.0473 - acc: 0.1787\n",
      "Epoch 3/100\n",
      "150182/150182 [==============================] - 172s 1ms/sample - loss: 4.7507 - acc: 0.2038\n",
      "Epoch 4/100\n",
      "150182/150182 [==============================] - 163s 1ms/sample - loss: 4.5374 - acc: 0.2179\n",
      "Epoch 5/100\n",
      "150182/150182 [==============================] - 169s 1ms/sample - loss: 4.3652 - acc: 0.2280\n",
      "Epoch 6/100\n",
      "150182/150182 [==============================] - 214s 1ms/sample - loss: 4.2086 - acc: 0.2379\n",
      "Epoch 7/100\n",
      "150182/150182 [==============================] - 203s 1ms/sample - loss: 4.0685 - acc: 0.2468\n",
      "Epoch 8/100\n",
      "150182/150182 [==============================] - 188s 1ms/sample - loss: 3.9450 - acc: 0.2563\n",
      "Epoch 9/100\n",
      "150182/150182 [==============================] - 153s 1ms/sample - loss: 3.8349 - acc: 0.2655\n",
      "Epoch 10/100\n",
      "150182/150182 [==============================] - 169s 1ms/sample - loss: 3.7355 - acc: 0.2732\n",
      "Epoch 11/100\n",
      "150182/150182 [==============================] - 184s 1ms/sample - loss: 3.6450 - acc: 0.2805\n",
      "Epoch 12/100\n",
      "150182/150182 [==============================] - 167s 1ms/sample - loss: 3.5598 - acc: 0.2885\n",
      "Epoch 13/100\n",
      "150182/150182 [==============================] - 137s 912us/sample - loss: 3.4853 - acc: 0.2958\n",
      "Epoch 14/100\n",
      "150182/150182 [==============================] - 155s 1ms/sample - loss: 3.4154 - acc: 0.3020\n",
      "Epoch 15/100\n",
      "150182/150182 [==============================] - 145s 966us/sample - loss: 3.3513 - acc: 0.3085\n",
      "Epoch 16/100\n",
      "150182/150182 [==============================] - 171s 1ms/sample - loss: 3.2913 - acc: 0.3147\n",
      "Epoch 17/100\n",
      "150182/150182 [==============================] - 147s 977us/sample - loss: 3.2339 - acc: 0.3205\n",
      "Epoch 18/100\n",
      "150182/150182 [==============================] - 161s 1ms/sample - loss: 3.1816 - acc: 0.3267\n",
      "Epoch 19/100\n",
      "150182/150182 [==============================] - 148s 987us/sample - loss: 3.1313 - acc: 0.3319\n",
      "Epoch 20/100\n",
      "150182/150182 [==============================] - 150s 1000us/sample - loss: 3.0861 - acc: 0.3381\n",
      "Epoch 21/100\n",
      "150182/150182 [==============================] - 153s 1ms/sample - loss: 3.0406 - acc: 0.3433\n",
      "Epoch 22/100\n",
      "150182/150182 [==============================] - 139s 927us/sample - loss: 2.9982 - acc: 0.3490\n",
      "Epoch 23/100\n",
      "150182/150182 [==============================] - 149s 989us/sample - loss: 2.9581 - acc: 0.3541\n",
      "Epoch 24/100\n",
      "150182/150182 [==============================] - 145s 965us/sample - loss: 2.9192 - acc: 0.3594\n",
      "Epoch 25/100\n",
      "150182/150182 [==============================] - 150s 1ms/sample - loss: 2.8822 - acc: 0.3646\n",
      "Epoch 26/100\n",
      "150182/150182 [==============================] - 163s 1ms/sample - loss: 2.8438 - acc: 0.3705\n",
      "Epoch 27/100\n",
      "150182/150182 [==============================] - 169s 1ms/sample - loss: 2.8071 - acc: 0.3765\n",
      "Epoch 28/100\n",
      "150182/150182 [==============================] - 172s 1ms/sample - loss: 2.7722 - acc: 0.3817\n",
      "Epoch 29/100\n",
      "150182/150182 [==============================] - 203s 1ms/sample - loss: 2.7402 - acc: 0.3855\n",
      "Epoch 30/100\n",
      "150182/150182 [==============================] - 210s 1ms/sample - loss: 2.7064 - acc: 0.3917\n",
      "Epoch 31/100\n",
      "150182/150182 [==============================] - 173s 1ms/sample - loss: 2.6749 - acc: 0.3957\n",
      "Epoch 32/100\n",
      "150182/150182 [==============================] - 200s 1ms/sample - loss: 2.6436 - acc: 0.4011\n",
      "Epoch 33/100\n",
      "150182/150182 [==============================] - 187s 1ms/sample - loss: 2.6122 - acc: 0.4058\n",
      "Epoch 34/100\n",
      "150182/150182 [==============================] - 189s 1ms/sample - loss: 2.5823 - acc: 0.4119\n",
      "Epoch 35/100\n",
      "150182/150182 [==============================] - 189s 1ms/sample - loss: 2.5501 - acc: 0.4167\n",
      "Epoch 36/100\n",
      "150182/150182 [==============================] - 154s 1ms/sample - loss: 2.5216 - acc: 0.4214s - l\n",
      "Epoch 37/100\n",
      "150182/150182 [==============================] - 151s 1ms/sample - loss: 2.4946 - acc: 0.4261\n",
      "Epoch 38/100\n",
      "150182/150182 [==============================] - 148s 986us/sample - loss: 2.4657 - acc: 0.4315\n",
      "Epoch 39/100\n",
      "150182/150182 [==============================] - 152s 1ms/sample - loss: 2.4373 - acc: 0.4362\n",
      "Epoch 40/100\n",
      "150182/150182 [==============================] - 152s 1ms/sample - loss: 2.4118 - acc: 0.4415\n",
      "Epoch 41/100\n",
      "150182/150182 [==============================] - 161s 1ms/sample - loss: 2.3846 - acc: 0.4454\n",
      "Epoch 42/100\n",
      "150182/150182 [==============================] - 148s 988us/sample - loss: 2.3596 - acc: 0.4498\n",
      "Epoch 43/100\n",
      "150182/150182 [==============================] - 153s 1ms/sample - loss: 2.3336 - acc: 0.4553\n",
      "Epoch 44/100\n",
      "150182/150182 [==============================] - 146s 973us/sample - loss: 2.3084 - acc: 0.4592\n",
      "Epoch 45/100\n",
      "150182/150182 [==============================] - 145s 965us/sample - loss: 2.2849 - acc: 0.4626\n",
      "Epoch 46/100\n",
      "150182/150182 [==============================] - 153s 1ms/sample - loss: 2.2576 - acc: 0.4681\n",
      "Epoch 47/100\n",
      "150182/150182 [==============================] - 137s 912us/sample - loss: 2.2345 - acc: 0.4719\n",
      "Epoch 48/100\n",
      "150182/150182 [==============================] - 137s 915us/sample - loss: 2.2120 - acc: 0.4761\n",
      "Epoch 49/100\n",
      "150182/150182 [==============================] - 138s 917us/sample - loss: 2.1873 - acc: 0.4806\n",
      "Epoch 50/100\n",
      "150182/150182 [==============================] - 138s 921us/sample - loss: 2.1635 - acc: 0.4852\n",
      "Epoch 51/100\n",
      "150182/150182 [==============================] - 139s 924us/sample - loss: 2.1434 - acc: 0.4892\n",
      "Epoch 52/100\n",
      "150182/150182 [==============================] - 139s 926us/sample - loss: 2.1180 - acc: 0.4944\n",
      "Epoch 53/100\n",
      "150182/150182 [==============================] - 144s 956us/sample - loss: 2.0978 - acc: 0.4977\n",
      "Epoch 54/100\n",
      "150182/150182 [==============================] - 141s 940us/sample - loss: 2.0767 - acc: 0.5030\n",
      "Epoch 55/100\n",
      "150182/150182 [==============================] - 157s 1ms/sample - loss: 2.0536 - acc: 0.5063\n",
      "Epoch 56/100\n",
      "150182/150182 [==============================] - 182s 1ms/sample - loss: 2.0323 - acc: 0.5100\n",
      "Epoch 57/100\n",
      "150182/150182 [==============================] - 150s 1ms/sample - loss: 2.0122 - acc: 0.5146\n",
      "Epoch 58/100\n",
      "150182/150182 [==============================] - 156s 1ms/sample - loss: 1.9925 - acc: 0.5184\n",
      "Epoch 59/100\n",
      "150182/150182 [==============================] - 170s 1ms/sample - loss: 2.0232 - acc: 0.5142\n",
      "Epoch 60/100\n",
      "150182/150182 [==============================] - 169s 1ms/sample - loss: 2.3797 - acc: 0.4569\n",
      "Epoch 61/100\n",
      "150182/150182 [==============================] - 184s 1ms/sample - loss: 2.3204 - acc: 0.4513\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150182/150182 [==============================] - 150s 996us/sample - loss: 2.1512 - acc: 0.4847\n",
      "Epoch 63/100\n",
      "150182/150182 [==============================] - 169s 1ms/sample - loss: 2.0986 - acc: 0.4957\n",
      "Epoch 64/100\n",
      "150182/150182 [==============================] - 168s 1ms/sample - loss: 2.0660 - acc: 0.5022\n",
      "Epoch 65/100\n",
      "150182/150182 [==============================] - 169s 1ms/sample - loss: 2.0167 - acc: 0.5118\n",
      "Epoch 66/100\n",
      "150182/150182 [==============================] - 156s 1ms/sample - loss: 1.9774 - acc: 0.5206\n",
      "Epoch 67/100\n",
      "150182/150182 [==============================] - 187s 1ms/sample - loss: 1.9526 - acc: 0.5249\n",
      "Epoch 68/100\n",
      "150182/150182 [==============================] - 175s 1ms/sample - loss: 1.9335 - acc: 0.5281\n",
      "Epoch 69/100\n",
      "150182/150182 [==============================] - 176s 1ms/sample - loss: 1.9101 - acc: 0.5334\n",
      "Epoch 70/100\n",
      "150182/150182 [==============================] - 190s 1ms/sample - loss: 1.8903 - acc: 0.5373\n",
      "Epoch 71/100\n",
      "150182/150182 [==============================] - 173s 1ms/sample - loss: 1.8751 - acc: 0.5396\n",
      "Epoch 72/100\n",
      "150182/150182 [==============================] - 170s 1ms/sample - loss: 2.2068 - acc: 0.4815\n",
      "Epoch 73/100\n",
      "150182/150182 [==============================] - 167s 1ms/sample - loss: 2.2070 - acc: 0.4681\n",
      "Epoch 74/100\n",
      "150182/150182 [==============================] - 182s 1ms/sample - loss: 2.0783 - acc: 0.4967\n",
      "Epoch 75/100\n",
      "150182/150182 [==============================] - 181s 1ms/sample - loss: 2.0105 - acc: 0.5109\n",
      "Epoch 76/100\n",
      "150182/150182 [==============================] - 183s 1ms/sample - loss: 1.9399 - acc: 0.5257\n",
      "Epoch 77/100\n",
      "150182/150182 [==============================] - 162s 1ms/sample - loss: 1.9218 - acc: 0.5290\n",
      "Epoch 78/100\n",
      "150182/150182 [==============================] - 180s 1ms/sample - loss: 1.8806 - acc: 0.5377\n",
      "Epoch 79/100\n",
      "150182/150182 [==============================] - 171s 1ms/sample - loss: 1.8354 - acc: 0.5476\n",
      "Epoch 80/100\n",
      "150182/150182 [==============================] - 175s 1ms/sample - loss: 1.8254 - acc: 0.5498\n",
      "Epoch 81/100\n",
      "150182/150182 [==============================] - 162s 1ms/sample - loss: 1.8615 - acc: 0.5388\n",
      "Epoch 82/100\n",
      "150182/150182 [==============================] - 159s 1ms/sample - loss: 1.7957 - acc: 0.5552\n",
      "Epoch 83/100\n",
      "150182/150182 [==============================] - 162s 1ms/sample - loss: 1.7710 - acc: 0.5607\n",
      "Epoch 84/100\n",
      "150182/150182 [==============================] - 173s 1ms/sample - loss: 1.7573 - acc: 0.5629\n",
      "Epoch 85/100\n",
      "150182/150182 [==============================] - 171s 1ms/sample - loss: 1.7406 - acc: 0.5673\n",
      "Epoch 86/100\n",
      "150182/150182 [==============================] - 173s 1ms/sample - loss: 1.7247 - acc: 0.5707\n",
      "Epoch 87/100\n",
      "150182/150182 [==============================] - 167s 1ms/sample - loss: 1.7317 - acc: 0.5683\n",
      "Epoch 88/100\n",
      "150182/150182 [==============================] - 189s 1ms/sample - loss: 1.7049 - acc: 0.5744\n",
      "Epoch 89/100\n",
      "150182/150182 [==============================] - 169s 1ms/sample - loss: 1.6837 - acc: 0.5778\n",
      "Epoch 90/100\n",
      "  1536/150182 [..............................] - ETA: 3:12 - loss: 1.6062 - acc: 0.6009"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b7f5ebc20815>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(torah_sequences)\n",
    "sequences = tokenizer.texts_to_sequences(torah_sequences)\n",
    "\n",
    "# vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    " \n",
    "# separate into input and output\n",
    "sequences = array(sequences)\n",
    "X, y = sequences[:,:-1], sequences[:,-1]\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "seq_length = X.shape[1]\n",
    " \n",
    "# define model\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, 50, input_length=seq_length),\n",
    "    LSTM(100, return_sequences=True),\n",
    "    LSTM(100),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "print(model.summary())\n",
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit model\n",
    "model.fit(X, y, batch_size=128, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # save the model to file\n",
    "# model.save('torah_model.hdf5')\n",
    "# # save the tokenizer\n",
    "# pickle.dump(tokenizer, open('torah_tokenizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
